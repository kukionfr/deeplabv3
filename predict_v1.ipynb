{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GP0U\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = tf.keras.layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = tf.keras.Input(shape=(image_size, image_size, 3))\n",
    "    resnet50 = tf.keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "    input_a = tf.keras.layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = tf.keras.layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return tf.keras.Model(inputs=model_input, outputs=model_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def _time(f):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        start=time()\n",
    "        r=f(*args,**kwargs)\n",
    "        end=time()\n",
    "        print(\"%s timed %f\" %(f.__name__,end-start))\n",
    "        return r\n",
    "    return wrapper\n",
    "\n",
    "@_time\n",
    "def reshape_split(image:np.ndarray,kernel_size:tuple):\n",
    "    img_height,img_width,channels=image.shape\n",
    "    tile_height,tile_width = kernel_size\n",
    "    tiled_array = image.reshape(img_height//tile_height,\n",
    "                                tile_height,\n",
    "                                img_width//tile_width,\n",
    "                                tile_width,\n",
    "                                channels)\n",
    "    tiled_array = tiled_array.swapaxes(1,2)\n",
    "    return tiled_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "Image.open = _time(Image.open)\n",
    "np.pad = _time(np.pad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 1024\n",
    "NUM_CLASSES = 13\n",
    "BATCH_SIZE = 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2963cbbb220>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest1 = tf.train.latest_checkpoint('fold_1')\n",
    "model1 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model1.load_weights(latest1)\n",
    "\n",
    "latest2 = tf.train.latest_checkpoint('fold_2')\n",
    "model2 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model2.load_weights(latest2)\n",
    "\n",
    "latest3 = tf.train.latest_checkpoint('fold_3')\n",
    "model3 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model3.load_weights(latest3)\n",
    "\n",
    "latest4 = tf.train.latest_checkpoint('fold_4')\n",
    "model4 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model4.load_weights(latest4)\n",
    "\n",
    "latest5 = tf.train.latest_checkpoint('fold_5')\n",
    "model5 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model5.load_weights(latest5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\109.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\12.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\120.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\132.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\14.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\147.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\155.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\16.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\17.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\194.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\21.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\238.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\264.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\287.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\29.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\297.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\303.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\330.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\334.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\335.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\363.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\379.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\49.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\57.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\62.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\8.tif']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\deeplab_trainingset\\tif'\n",
    "dst = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\deeplab_trainingset\\v11_fold1\\prediction'\n",
    "imlist = glob(os.path.join(src,'*.tif'))\n",
    "imlist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open timed 0.081801\n",
      "pad timed 0.217789\n",
      "reshape_split timed 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "impth = imlist[0] # Need to loop the whole thing below\n",
    "base,imnm = os.path.split(impth)\n",
    "imobj = Image.open(os.path.join(src,imnm))\n",
    "# Image to Array\n",
    "imnp = np.array(imobj)\n",
    "img_height,img_width,channels=imnp.shape\n",
    "tile_height, tile_width = (1024,1024)\n",
    "# Padding\n",
    "imnpr = np.pad(imnp, pad_width=[(0, tile_height-img_height%tile_height),(0, tile_width-img_width%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "# imnpr = imnpr / 127.5 - 1 #normalize [-1 1]\n",
    "imnpr = imnpr / 255 #normalize [0 1]\n",
    "img_height2,img_width2,channels=imnpr.shape\n",
    "# Tile\n",
    "tiles = reshape_split(imnpr, (1024,1024))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad timed 0.193176\n",
      "reshape_split timed 0.000000\n",
      "pad timed 0.212193\n",
      "reshape_split timed 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Pad and Tile for horz and vert shifts\n",
    "imnphorz = imnp[512:,:,:] #this is actually vertical\n",
    "img_heighthorz,img_widthhorz,channels=imnphorz.shape\n",
    "imnphorzpad =np.pad(imnphorz, pad_width=[(0, tile_height-img_heighthorz%tile_height),(0, tile_width-img_widthhorz%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "imnphorzpad = imnphorzpad / 255\n",
    "tileshorz=reshape_split(imnphorzpad, (1024,1024))\n",
    "imnpvert = imnp[:,512:,:]\n",
    "img_heightvert,img_widthvert,channels=imnpvert.shape\n",
    "imnpvertpad =np.pad(imnpvert, pad_width=[(0, tile_height-img_heightvert%tile_height),(0, tile_width-img_widthvert%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "imnpvertpad = imnpvertpad / 255\n",
    "tilesvert=reshape_split(imnpvertpad, (1024,1024))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad timed 0.227219\n",
      "reshape_split timed 0.000000\n"
     ]
    }
   ],
   "source": [
    "imnphv = imnp[512:,512:,:]\n",
    "img_heighthv,img_widthhv,channels=imnphv.shape\n",
    "imnphvpad =np.pad(imnphv, pad_width=[(0, tile_height-img_heighthv%tile_height),(0, tile_width-img_widthhv%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "imnphvpad = imnphvpad / 255\n",
    "tileshv=reshape_split(imnphvpad, (1024,1024))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "@_time\n",
    "def popularvote(arr):\n",
    "    #popular vote stack of 2d images to 2d\n",
    "    axis = 0\n",
    "    u, indices = np.unique(arr, return_inverse=True)\n",
    "    return u[np.argmax(np.apply_along_axis(np.bincount, axis, indices.reshape(arr.shape),None, np.max(indices) + 1), axis=axis)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def mask3d(image3d):\n",
    "    mask2d = np.zeros_like(image3d[0])\n",
    "    a=int(len(mask2d)/4)\n",
    "    mask2d[a:a*3,a:a*3]=1\n",
    "    mask3d = np.broadcast_to(mask2d, image3d.shape)\n",
    "    image3d=np.multiply(image3d,mask3d)\n",
    "    return image3d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def mask4d(image4d):\n",
    "    mask2d = np.zeros_like(image4d[0])\n",
    "    a=int(len(mask2d)/4)\n",
    "    mask2d[a:a*3,a:a*3]=1\n",
    "    mask4d = np.broadcast_to(mask2d, image4d.shape)\n",
    "    image4d=np.multiply(image4d,mask4d)\n",
    "    return image4d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "@_time\n",
    "def classifyDL(tiles):\n",
    "    wsipop = np.zeros_like(tiles).astype(np.float32)\n",
    "    wsipop = wsipop[:,:,:,:,0]\n",
    "    for idx,row in enumerate(tiles):\n",
    "        pred_dataset = tf.data.Dataset.from_tensor_slices(row) #this function is only for small dataset fucking hell; only works for a row of image.\n",
    "        pred_dataset = pred_dataset.batch(4, drop_remainder=False)\n",
    "        start = time()\n",
    "        predictions1 = model1.predict(pred_dataset)\n",
    "        predictions2 = model2.predict(pred_dataset)\n",
    "        predictions3 = model3.predict(pred_dataset)\n",
    "        predictions4 = model4.predict(pred_dataset)\n",
    "        predictions5 = model5.predict(pred_dataset)\n",
    "        print('prediction time:',time()-start)\n",
    "\n",
    "        # start = time()\n",
    "        predictions1 = np.squeeze(predictions1)\n",
    "        predictions2 = np.squeeze(predictions2)\n",
    "        predictions3 = np.squeeze(predictions3)\n",
    "        predictions4 = np.squeeze(predictions4)\n",
    "        predictions5 = np.squeeze(predictions5)\n",
    "        #Method A: most confident\n",
    "        # predictions_comb = np.concatenate ([predictions1,predictions2,predictions3,predictions4,predictions5],axis=-1)\n",
    "        # predictions_comb = np.argmax(predictions_comb, axis=3)\n",
    "        # predictions_comb = np.mod(predictions_comb,13)\n",
    "        # wsicomb[idx] = predictions_comb\n",
    "        # print('confident method time:',time()-start)\n",
    "\n",
    "        #Method B: popular vote\n",
    "        predictions1 = np.argmax(predictions1, axis=3)\n",
    "        predictions2 = np.argmax(predictions2, axis=3)\n",
    "        predictions3 = np.argmax(predictions3, axis=3)\n",
    "        predictions4 = np.argmax(predictions4, axis=3)\n",
    "        predictions5 = np.argmax(predictions5, axis=3)\n",
    "        predictions_popular = popularvote(np.stack([predictions1,predictions2,predictions3,predictions4,predictions5]))\n",
    "        predictions_popular_masked = mask3d(predictions_popular)\n",
    "        wsipop[idx] = predictions_popular_masked\n",
    "\n",
    "    return wsipop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "@_time\n",
    "def classifyDL_v2(tiles):\n",
    "    wsiavg = np.zeros_like(tiles).astype('uint')\n",
    "    wsiavg = wsiavg[:,:,:,:,0]\n",
    "    wsiavg = np.repeat(wsiavg[:,:,:,:,np.newaxis],13,axis=4) #pre-allocate probability map\n",
    "    for idx,row in enumerate(tiles):\n",
    "        print('row: ',idx+1,'/',len(tiles))\n",
    "        pred_dataset = tf.data.Dataset.from_tensor_slices(row) #this function is only for small dataset fucking hell; only works for a row of image.\n",
    "        pred_dataset = pred_dataset.batch(4, drop_remainder=False)\n",
    "\n",
    "        predictions1 = model1.predict(pred_dataset)\n",
    "        predictions2 = model2.predict(pred_dataset)\n",
    "        predictions3 = model3.predict(pred_dataset)\n",
    "        predictions4 = model4.predict(pred_dataset)\n",
    "        predictions5 = model5.predict(pred_dataset)\n",
    "\n",
    "        predictions1 = np.squeeze(predictions1)\n",
    "        predictions2 = np.squeeze(predictions2)\n",
    "        predictions3 = np.squeeze(predictions3)\n",
    "        predictions4 = np.squeeze(predictions4)\n",
    "        predictions5 = np.squeeze(predictions5)\n",
    "\n",
    "        prediction_avg = np.average(np.stack([predictions1,predictions2,predictions3,predictions4,predictions5]),axis=0)\n",
    "        # prediction_avg = mask3d(np.argmax(prediction_avg, axis=3).astype('uint'))\n",
    "        wsiavg[idx] = prediction_avg\n",
    "    return wsiavg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 18\n",
      "row:  2 / 18\n",
      "row:  3 / 18\n",
      "row:  4 / 18\n",
      "row:  5 / 18\n",
      "row:  6 / 18\n",
      "row:  7 / 18\n",
      "row:  8 / 18\n",
      "row:  9 / 18\n",
      "row:  10 / 18\n",
      "row:  11 / 18\n",
      "row:  12 / 18\n",
      "row:  13 / 18\n",
      "row:  14 / 18\n",
      "row:  15 / 18\n",
      "row:  16 / 18\n",
      "row:  17 / 18\n",
      "row:  18 / 18\n",
      "classifyDL_v2 timed 238.255613\n"
     ]
    }
   ],
   "source": [
    "wsipop = classifyDL_v2(tiles)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 17\n",
      "row:  2 / 17\n",
      "row:  3 / 17\n",
      "row:  4 / 17\n",
      "row:  5 / 17\n",
      "row:  6 / 17\n",
      "row:  7 / 17\n",
      "row:  8 / 17\n",
      "row:  9 / 17\n",
      "row:  10 / 17\n",
      "row:  11 / 17\n",
      "row:  12 / 17\n",
      "row:  13 / 17\n",
      "row:  14 / 17\n",
      "row:  15 / 17\n",
      "row:  16 / 17\n",
      "row:  17 / 17\n",
      "classifyDL_v2 timed 214.550248\n"
     ]
    }
   ],
   "source": [
    "wsipop_h = classifyDL_v2(tileshorz)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 18\n",
      "row:  2 / 18\n",
      "row:  3 / 18\n",
      "row:  4 / 18\n",
      "row:  5 / 18\n",
      "row:  6 / 18\n",
      "row:  7 / 18\n",
      "row:  8 / 18\n",
      "row:  9 / 18\n",
      "row:  10 / 18\n",
      "row:  11 / 18\n",
      "row:  12 / 18\n",
      "row:  13 / 18\n",
      "row:  14 / 18\n",
      "row:  15 / 18\n",
      "row:  16 / 18\n",
      "row:  17 / 18\n",
      "row:  18 / 18\n",
      "classifyDL_v2 timed 236.203173\n"
     ]
    }
   ],
   "source": [
    "wsipop_v = classifyDL_v2(tilesvert)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 17\n",
      "row:  2 / 17\n",
      "row:  3 / 17\n",
      "row:  4 / 17\n",
      "row:  5 / 17\n",
      "row:  6 / 17\n",
      "row:  7 / 17\n",
      "row:  8 / 17\n",
      "row:  9 / 17\n",
      "row:  10 / 17\n",
      "row:  11 / 17\n",
      "row:  12 / 17\n",
      "row:  13 / 17\n",
      "row:  14 / 17\n",
      "row:  15 / 17\n",
      "row:  16 / 17\n",
      "row:  17 / 17\n",
      "classifyDL_v2 timed 248.081260\n"
     ]
    }
   ],
   "source": [
    "wsipop_hv = classifyDL_v2(tileshv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory size of numpy array in Gb: 25.518145536000002\n"
     ]
    }
   ],
   "source": [
    "# memory size of numpy array in bytes\n",
    "print(\"Memory size of numpy array in Gb:\",\n",
    "      wsipop.size * wsipop.itemsize * 1e-9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#stitch tiles into wsi\n",
    "def stitch(tiles,img_height,img_width,img_height2,img_width2,channels):\n",
    "    wsi = tiles.swapaxes(1,2)\n",
    "    wsi = wsi.reshape(img_height2,img_width2,channels) #tiles are padded, so use padded image size to stitch\n",
    "    wsi = wsi[:img_height,:img_width,:] #remove pad\n",
    "    return np.squeeze(wsi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6066025836 into shape (18432,26624,13)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [28]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m img_height,img_width,channels\u001B[38;5;241m=\u001B[39mimnp\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m      2\u001B[0m img_height2,img_width2,channels\u001B[38;5;241m=\u001B[39mimnpr\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m----> 3\u001B[0m wsipopst \u001B[38;5;241m=\u001B[39m \u001B[43mstitch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwsipop\u001B[49m\u001B[43m,\u001B[49m\u001B[43mimg_height\u001B[49m\u001B[43m,\u001B[49m\u001B[43mimg_width\u001B[49m\u001B[43m,\u001B[49m\u001B[43mimg_height2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mimg_width2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m13\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36mstitch\u001B[1;34m(tiles, img_height, img_width, img_height2, img_width2, channels)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstitch\u001B[39m(tiles,img_height,img_width,img_height2,img_width2,channels):\n\u001B[0;32m      3\u001B[0m     wsi \u001B[38;5;241m=\u001B[39m tiles\u001B[38;5;241m.\u001B[39mswapaxes(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m     wsi \u001B[38;5;241m=\u001B[39m \u001B[43mwsi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_height2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mimg_width2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#tiles are padded, so use padded image size to stitch\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     wsi \u001B[38;5;241m=\u001B[39m wsi[:img_height,:img_width,:] \u001B[38;5;66;03m#remove pad\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39msqueeze(wsi)\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 6066025836 into shape (18432,26624,13)"
     ]
    }
   ],
   "source": [
    "img_height,img_width,channels=imnp.shape\n",
    "img_height2,img_width2,channels=imnpr.shape\n",
    "wsipopst = stitch(wsipop,img_height,img_width,img_height2,img_width2,channels=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "img_height,img_width,channels=imnphorz.shape\n",
    "img_height2,img_width2,channels=imnphorzpad.shape\n",
    "wsipop_h = stitch(wsipop_h,img_height,img_width,img_height2,img_width2,channels=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "img_height,img_width,channels=imnpvert.shape\n",
    "img_height2,img_width2,channels=imnpvertpad.shape\n",
    "wsipop_v = stitch(wsipop_v,img_height,img_width,img_height2,img_width2,channels=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "img_height,img_width,channels=imnphv.shape\n",
    "img_height2,img_width2,channels=imnphvpad.shape\n",
    "wsipop_hv = stitch(wsipop_hv,img_height,img_width,img_height2,img_width2,channels=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "wsipop = wsipop[512:,512:]\n",
    "wsipop_h = wsipop_h[:,512:]\n",
    "wsipop_v = wsipop_v[512:,:]\n",
    "wsipop_t = wsipop+wsipop_h+wsipop_v+wsipop_hv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "#save mask into png\n",
    "png = Image.fromarray(np.squeeze(wsipop.astype('uint')))\n",
    "png = png.convert(\"L\")\n",
    "png.save(os.path.join(dst,imnm.replace('.tif','base.png')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "png = Image.fromarray(np.squeeze(wsipop_h.astype('uint')))\n",
    "png = png.convert(\"L\")\n",
    "png.save(os.path.join(dst,imnm.replace('.tif','horz.png')))\n",
    "png = Image.fromarray(np.squeeze(wsipop_v.astype('uint')))\n",
    "png = png.convert(\"L\")\n",
    "png.save(os.path.join(dst,imnm.replace('.tif','vert.png')))\n",
    "png = Image.fromarray(np.squeeze(wsipop_t.astype('uint')))\n",
    "png = png.convert(\"L\")\n",
    "png.save(os.path.join(dst,imnm.replace('.tif','sumd.png')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}