{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def _time(f):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        start=time()\n",
    "        r=f(*args,**kwargs)\n",
    "        end=time()\n",
    "        print(\"%s timed %f\" %(f.__name__,end-start))\n",
    "        return r\n",
    "    return wrapper\n",
    "\n",
    "Image.open = _time(Image.open)\n",
    "np.pad = _time(np.pad)\n",
    "# tf.keras.Model = _time(tf.keras.Model) #too quick to time it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GP0U\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = tf.keras.layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = tf.keras.Input(shape=(image_size, image_size, 3))\n",
    "    resnet50 = tf.keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "    input_a = tf.keras.layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = tf.keras.layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return tf.keras.Model(inputs=model_input, outputs=model_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "@_time\n",
    "def reshape_split(image:np.ndarray,kernel_size:tuple):\n",
    "    img_height,img_width,channels=image.shape\n",
    "    tile_height,tile_width = kernel_size\n",
    "    tiled_array = image.reshape(img_height//tile_height,\n",
    "                                tile_height,\n",
    "                                img_width//tile_width,\n",
    "                                tile_width,\n",
    "                                channels)\n",
    "    tiled_array = tiled_array.swapaxes(1,2)\n",
    "    return tiled_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 1024\n",
    "NUM_CLASSES = 13\n",
    "BATCH_SIZE = 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1a72c311340>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest1 = tf.train.latest_checkpoint('fold_1')\n",
    "model1 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model1.load_weights(latest1)\n",
    "\n",
    "latest2 = tf.train.latest_checkpoint('fold_2')\n",
    "model2 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model2.load_weights(latest2)\n",
    "\n",
    "latest3 = tf.train.latest_checkpoint('fold_3')\n",
    "model3 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model3.load_weights(latest3)\n",
    "\n",
    "latest4 = tf.train.latest_checkpoint('fold_4')\n",
    "model4 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model4.load_weights(latest4)\n",
    "\n",
    "latest5 = tf.train.latest_checkpoint('fold_5')\n",
    "model5 = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "model5.load_weights(latest5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\109.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\12.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\120.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\132.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\14.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\147.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\155.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\16.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\17.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\194.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\21.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\238.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\264.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\287.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\29.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\297.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\303.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\330.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\334.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\335.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\363.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\379.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\49.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\57.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\62.tif',\n '\\\\\\\\fatherserverdw\\\\Q\\\\research\\\\images\\\\skin_aging\\\\deeplab_trainingset\\\\tif\\\\8.tif']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\deeplab_trainingset\\tif'\n",
    "dst = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\deeplab_trainingset\\v11_fold1\\prediction'\n",
    "imlist = glob(os.path.join(src,'*.tif'))\n",
    "imlist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from skimage.filters import window\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.fft import fft2, fftshift\n",
    "from skimage import img_as_float\n",
    "from skimage.data import astronaut\n",
    "image = img_as_float(rgb2gray(astronaut()))\n",
    "\n",
    "wimage = image * window('hann', image.shape)\n",
    "\n",
    "image_f = np.abs(fftshift(fft2(image)))\n",
    "wimage_f = np.abs(fftshift(fft2(wimage)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax = axes.ravel()\n",
    "ax[0].set_title(\"Original image\")\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[1].set_title(\"Windowed image\")\n",
    "ax[1].imshow(wimage, cmap='gray')\n",
    "ax[2].set_title(\"Original FFT (frequency)\")\n",
    "ax[2].imshow(np.log(image_f), cmap='magma')\n",
    "ax[3].set_title(\"Window + FFT (frequency)\")\n",
    "ax[3].imshow(np.log(wimage_f), cmap='magma')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open timed 0.012011\n",
      "pad timed 0.202458\n",
      "reshape_split timed 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "impth = imlist[0] # Need to loop the whole thing below\n",
    "base,imnm = os.path.split(impth)\n",
    "imobj = Image.open(os.path.join(src,imnm))\n",
    "# Image to Array\n",
    "imnp = np.array(imobj)\n",
    "imobj.close()\n",
    "h,w,_=imnp.shape\n",
    "tile_height, tile_width = (1024,1024)\n",
    "# Padding\n",
    "imnpr = np.pad(imnp, pad_width=[(0, tile_height-h%tile_height),(0, tile_width-w%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "# imnpr = imnpr / 127.5 - 1 #normalize [-1 1]\n",
    "imnpr = imnpr / 255 #normalize [0 1]\n",
    "img_height2,img_width2,channels=imnpr.shape\n",
    "# Tile\n",
    "tiles = reshape_split(imnpr, (1024,1024))\n",
    "h2,w2,_=imnpr.shape\n",
    "del imnpr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad timed 0.244246\n",
      "reshape_split timed 0.000000\n",
      "pad timed 0.217750\n",
      "reshape_split timed 0.000000\n",
      "pad timed 0.256497\n",
      "reshape_split timed 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Pad and Tile for horz and vert shifts\n",
    "imnphorz = imnp[512:,:,:] #this is actually vertical\n",
    "h_h,h_w,_=imnphorz.shape\n",
    "imnphorzpad =np.pad(imnphorz, pad_width=[(0, tile_height-h_h%tile_height),(0, tile_width-h_w%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "imnphorzpad = imnphorzpad / 255\n",
    "tileshorz=reshape_split(imnphorzpad, (1024,1024))\n",
    "h_h2,h_w2,_=imnphorzpad.shape\n",
    "del imnphorz,imnphorzpad\n",
    "\n",
    "imnpvert = imnp[:,512:,:]\n",
    "v_h,v_w,_=imnpvert.shape\n",
    "imnpvertpad =np.pad(imnpvert, pad_width=[(0, tile_height-v_h%tile_height),(0, tile_width-v_w%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "imnpvertpad = imnpvertpad / 255\n",
    "tilesvert=reshape_split(imnpvertpad, (1024,1024))\n",
    "v_h2,v_w2,_=imnpvertpad.shape\n",
    "del imnpvert,imnpvertpad\n",
    "\n",
    "imnphv = imnp[512:,512:,:]\n",
    "del imnp\n",
    "hv_h,hv_w,_=imnphv.shape\n",
    "imnphvpad =np.pad(imnphv, pad_width=[(0, tile_height-hv_h%tile_height),(0, tile_width-hv_w%tile_width),(0, 0)], mode='constant', constant_values=0)\n",
    "imnphvpad = imnphvpad / 255\n",
    "tileshv=reshape_split(imnphvpad, (1024,1024))\n",
    "hv_h2,hv_w2,_=imnphvpad.shape\n",
    "del imnphv,imnphvpad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "@_time\n",
    "def popularvote(arr):\n",
    "    #popular vote stack of 2d images to 2d\n",
    "    axis = 0\n",
    "    u, indices = np.unique(arr, return_inverse=True)\n",
    "    return u[np.argmax(np.apply_along_axis(np.bincount, axis, indices.reshape(arr.shape),None, np.max(indices) + 1), axis=axis)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def mask3d(image3d):\n",
    "    mask2d = np.zeros_like(image3d[0])\n",
    "    a=int(len(mask2d)/4)\n",
    "    mask2d[a:a*3,a:a*3]=1\n",
    "    mask3d = np.broadcast_to(mask2d, image3d.shape)\n",
    "    image3d=np.multiply(image3d,mask3d)\n",
    "    return image3d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def mask4d(image4d):\n",
    "    mask2d = np.zeros_like(image4d[0])\n",
    "    a=int(len(mask2d)/4)\n",
    "    mask2d[a:a*3,a:a*3]=1\n",
    "    mask4d = np.broadcast_to(mask2d, image4d.shape)\n",
    "    image4d=np.multiply(image4d,mask4d)\n",
    "    return image4d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "@_time\n",
    "def classifyDL(tiles):\n",
    "    wsipop = np.zeros_like(tiles).astype(np.float32)\n",
    "    wsipop = wsipop[:,:,:,:,0]\n",
    "    for idx,row in enumerate(tiles):\n",
    "        pred_dataset = tf.data.Dataset.from_tensor_slices(row) #this function is only for small dataset fucking hell; only works for a row of image.\n",
    "        pred_dataset = pred_dataset.batch(4, drop_remainder=False)\n",
    "        start = time()\n",
    "        predictions1 = model1.predict(pred_dataset)\n",
    "        predictions2 = model2.predict(pred_dataset)\n",
    "        predictions3 = model3.predict(pred_dataset)\n",
    "        predictions4 = model4.predict(pred_dataset)\n",
    "        predictions5 = model5.predict(pred_dataset)\n",
    "        print('prediction time:',time()-start)\n",
    "\n",
    "        # start = time()\n",
    "        predictions1 = np.squeeze(predictions1)\n",
    "        predictions2 = np.squeeze(predictions2)\n",
    "        predictions3 = np.squeeze(predictions3)\n",
    "        predictions4 = np.squeeze(predictions4)\n",
    "        predictions5 = np.squeeze(predictions5)\n",
    "        #Method A: most confident\n",
    "        # predictions_comb = np.concatenate ([predictions1,predictions2,predictions3,predictions4,predictions5],axis=-1)\n",
    "        # predictions_comb = np.argmax(predictions_comb, axis=3)\n",
    "        # predictions_comb = np.mod(predictions_comb,13)\n",
    "        # wsicomb[idx] = predictions_comb\n",
    "        # print('confident method time:',time()-start)\n",
    "\n",
    "        #Method B: popular vote\n",
    "        predictions1 = np.argmax(predictions1, axis=3)\n",
    "        predictions2 = np.argmax(predictions2, axis=3)\n",
    "        predictions3 = np.argmax(predictions3, axis=3)\n",
    "        predictions4 = np.argmax(predictions4, axis=3)\n",
    "        predictions5 = np.argmax(predictions5, axis=3)\n",
    "        predictions_popular = popularvote(np.stack([predictions1,predictions2,predictions3,predictions4,predictions5]))\n",
    "        predictions_popular_masked = mask3d(predictions_popular)\n",
    "        wsipop[idx] = predictions_popular_masked\n",
    "    return wsipop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "@_time\n",
    "def classifyDL_v2(tiles):\n",
    "    # wsiavg = np.zeros_like(tiles).astype('uint8')\n",
    "    wsiavg = np.zeros_like(tiles).astype(np.float16)\n",
    "    wsiavg = wsiavg[:,:,:,:,0]\n",
    "    wsiavg = np.repeat(wsiavg[:,:,:,:,np.newaxis],13,axis=4) #pre-allocate probability map\n",
    "    for idx,row in enumerate(tiles):\n",
    "        print('row: ',idx+1,'/',len(tiles))\n",
    "        pred_dataset = tf.data.Dataset.from_tensor_slices(row) #this function is only for small dataset fucking hell; only works for a row of image.\n",
    "        pred_dataset = pred_dataset.batch(4, drop_remainder=False)\n",
    "\n",
    "        predictions1 = model1.predict(pred_dataset)\n",
    "        predictions2 = model2.predict(pred_dataset)\n",
    "        predictions3 = model3.predict(pred_dataset)\n",
    "        predictions4 = model4.predict(pred_dataset)\n",
    "        predictions5 = model5.predict(pred_dataset)\n",
    "\n",
    "        predictions1 = np.squeeze(predictions1)\n",
    "        predictions2 = np.squeeze(predictions2)\n",
    "        predictions3 = np.squeeze(predictions3)\n",
    "        predictions4 = np.squeeze(predictions4)\n",
    "        predictions5 = np.squeeze(predictions5)\n",
    "\n",
    "        prediction_avg = np.average(np.stack([predictions1,predictions2,predictions3,predictions4,predictions5]),axis=0)\n",
    "        # prediction_avg = mask3d(np.argmax(prediction_avg, axis=3).astype('uint'))\n",
    "        wsiavg[idx] = prediction_avg\n",
    "    return wsiavg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 18\n",
      "row:  2 / 18\n",
      "row:  3 / 18\n",
      "row:  4 / 18\n",
      "row:  5 / 18\n",
      "row:  6 / 18\n",
      "row:  7 / 18\n",
      "row:  8 / 18\n",
      "row:  9 / 18\n",
      "row:  10 / 18\n",
      "row:  11 / 18\n",
      "row:  12 / 18\n",
      "row:  13 / 18\n",
      "row:  14 / 18\n",
      "row:  15 / 18\n",
      "row:  16 / 18\n",
      "row:  17 / 18\n",
      "row:  18 / 18\n",
      "classifyDL_v2 timed 238.493483\n"
     ]
    }
   ],
   "source": [
    "wsipop = classifyDL_v2(tiles)\n",
    "del tiles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 17\n",
      "row:  2 / 17\n",
      "row:  3 / 17\n",
      "row:  4 / 17\n",
      "row:  5 / 17\n",
      "row:  6 / 17\n",
      "row:  7 / 17\n",
      "row:  8 / 17\n",
      "row:  9 / 17\n",
      "row:  10 / 17\n",
      "row:  11 / 17\n",
      "row:  12 / 17\n",
      "row:  13 / 17\n",
      "row:  14 / 17\n",
      "row:  15 / 17\n",
      "row:  16 / 17\n",
      "row:  17 / 17\n",
      "classifyDL_v2 timed 207.728425\n"
     ]
    }
   ],
   "source": [
    "wsipop_h = classifyDL_v2(tileshorz)\n",
    "del tileshorz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 18\n",
      "row:  2 / 18\n",
      "row:  3 / 18\n",
      "row:  4 / 18\n",
      "row:  5 / 18\n",
      "row:  6 / 18\n",
      "row:  7 / 18\n",
      "row:  8 / 18\n",
      "row:  9 / 18\n",
      "row:  10 / 18\n",
      "row:  11 / 18\n",
      "row:  12 / 18\n",
      "row:  13 / 18\n",
      "row:  14 / 18\n",
      "row:  15 / 18\n",
      "row:  16 / 18\n",
      "row:  17 / 18\n",
      "row:  18 / 18\n",
      "classifyDL_v2 timed 212.106201\n"
     ]
    }
   ],
   "source": [
    "wsipop_v = classifyDL_v2(tilesvert)\n",
    "del tilesvert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  1 / 17\n",
      "row:  2 / 17\n",
      "row:  3 / 17\n",
      "row:  4 / 17\n",
      "row:  5 / 17\n",
      "row:  6 / 17\n",
      "row:  7 / 17\n",
      "row:  8 / 17\n",
      "row:  9 / 17\n",
      "row:  10 / 17\n",
      "row:  11 / 17\n",
      "row:  12 / 17\n",
      "row:  13 / 17\n",
      "row:  14 / 17\n",
      "row:  15 / 17\n",
      "row:  16 / 17\n",
      "row:  17 / 17\n",
      "classifyDL_v2 timed 200.127474\n"
     ]
    }
   ],
   "source": [
    "wsipop_hv = classifyDL_v2(tileshv)\n",
    "del tileshv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory size of numpy array in Gb: 12.759072768000001\n"
     ]
    }
   ],
   "source": [
    "# memory size of numpy array in bytes\n",
    "print(\"Memory size of numpy array in Gb:\",\n",
    "      wsipop.size * wsipop.itemsize * 1e-9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#stitch tiles into wsi\n",
    "def stitch(tiles,img_height,img_width,img_height2,img_width2,channels):\n",
    "    wsi = tiles.swapaxes(1,2)\n",
    "    wsi = wsi.reshape(img_height2,img_width2,channels) #tiles are padded, so use padded image size to stitch\n",
    "    wsi = wsi[:img_height,:img_width,:] #remove pad\n",
    "    return np.squeeze(wsi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "wsipop = stitch(wsipop,h,w,h2,w2,channels=13)\n",
    "wsipop_h = stitch(wsipop_h,h_h,h_w,h_h2,h_w2,channels=13)\n",
    "wsipop_v = stitch(wsipop_v,v_h,v_w,v_h2,v_w2,channels=13)\n",
    "wsipop_hv = stitch(wsipop_hv,hv_h,hv_w,hv_h2,hv_w2,channels=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "wsipop = wsipop[512:,512:,:]\n",
    "wsipop_h = wsipop_h[:,512:,:]\n",
    "wsipop_v = wsipop_v[512:,:,:]\n",
    "# wsipop_t = wsipop+wsipop_h+wsipop_v+wsipop_hv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "wsipop_t = np.mean(np.stack([wsipop,wsipop_h,wsipop_v,wsipop_hv]),dtype=np.float16,axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "wsipop_tt = np.argmax(wsipop_t, axis=2).astype('uint8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "wsipop_t = np.mean(np.stack([wsipop,wsipop_hv]),dtype=np.float16,axis=0)\n",
    "wsipop_small = np.argmax(wsipop_t, axis=2).astype('uint8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#save mask into png\n",
    "png = Image.fromarray(np.squeeze(wsipop_small))\n",
    "png = png.convert(\"L\")\n",
    "png.save(os.path.join(dst,imnm.replace('.tif','avgsm.png')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #save mask into png\n",
    "# png = Image.fromarray(np.squeeze(wsipop.astype('uint')))\n",
    "# png = png.convert(\"L\")\n",
    "# png.save(os.path.join(dst,imnm.replace('.tif','base.png')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# png = Image.fromarray(np.squeeze(wsipop_h.astype('uint')))\n",
    "# png = png.convert(\"L\")\n",
    "# png.save(os.path.join(dst,imnm.replace('.tif','horz.png')))\n",
    "# png = Image.fromarray(np.squeeze(wsipop_v.astype('uint')))\n",
    "# png = png.convert(\"L\")\n",
    "# png.save(os.path.join(dst,imnm.replace('.tif','vert.png')))\n",
    "# png = Image.fromarray(np.squeeze(wsipop_t.astype('uint')))\n",
    "# png = png.convert(\"L\")\n",
    "# png.save(os.path.join(dst,imnm.replace('.tif','sumd.png')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}